---
title: "My Journey in AI/ML: From Embedded Systems to RAG-based LLMs"
description: "Exploring the intersection of embedded systems and modern AI technologies"
author: "Revathy Venugopal"
date: "2025-09-21"
categories:
  - ai-ml
  - career
  - technology
  - python
image: "/assets/revathy.jpg"
---

## Introduction

My journey from embedded systems engineering to AI/ML development has been fascinating and unexpected. What started as a passion for automotive embedded systems has evolved into developing cutting-edge AI solutions, particularly RAG-based Large Language Models. Here's how my technical evolution unfolded and what I've learned along the way.

## The Foundation: Embedded Systems

My technical journey began with a deep dive into embedded systems during my Master's degree in Automotive Embedded Systems from ESIGELEC (France) and MAHE (India). This foundation taught me:

### Core Principles
- **Real-time Constraints**: Understanding the critical importance of timing in systems
- **Resource Optimization**: Working with limited memory and processing power
- **Safety-Critical Thinking**: Developing software where failures have real-world consequences
- **Hardware-Software Integration**: Bridging the gap between physical and digital worlds

### Technical Skills Acquired
```python
# Python-based data processing and analysis
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

def process_sensor_data(sensor_readings):
    """Process and analyze sensor data from automotive systems."""
    # Data preprocessing
    df = pd.DataFrame(sensor_readings)
    scaler = StandardScaler()
    normalized_data = scaler.fit_transform(df[['speed', 'temperature', 'pressure']])
    
    # Anomaly detection
    from sklearn.ensemble import IsolationForest
    iso_forest = IsolationForest(contamination=0.1)
    anomalies = iso_forest.fit_predict(normalized_data)
    
    return {
        'processed_data': normalized_data,
        'anomalies': anomalies,
        'summary_stats': df.describe()
    }
```

Working with automotive data analysis, implementing machine learning pipelines, and ensuring data quality gave me a solid foundation in systematic, robust software development.

## The Transition: Computer Vision and Robotics

During my internship at SITIA Robotique, I discovered the exciting world of computer vision and robotics. This was my first real exposure to AI/ML technologies:

### Key Projects
- **Computer Vision with TensorFlow**: Implemented CNN-based image classification for robot navigation
- **Path Planning**: Developed algorithms for real-time robot navigation using reinforcement learning
- **Sensor Fusion**: Combined camera and LiDAR data for robust perception using deep learning

### Technical Growth
```python
import tensorflow as tf
from tensorflow.keras import layers, models
import cv2
import numpy as np

class RobotVisionSystem:
    def __init__(self):
        self.model = self._build_cnn_model()
        
    def _build_cnn_model(self):
        """Build CNN model for obstacle classification."""
        model = models.Sequential([
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(128, (3, 3), activation='relu'),
            layers.GlobalAveragePooling2D(),
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(4, activation='softmax')  # 4 classes: safe, obstacle, person, vehicle
        ])
        
        model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        return model
    
    def detect_obstacles(self, frame):
        """Detect and classify obstacles in camera frame."""
        # Preprocess frame
        frame_resized = cv2.resize(frame, (224, 224))
        frame_normalized = frame_resized / 255.0
        frame_batch = np.expand_dims(frame_normalized, axis=0)
        
        # Predict
        predictions = self.model.predict(frame_batch)
        class_names = ['safe', 'obstacle', 'person', 'vehicle']
        
        predicted_class = class_names[np.argmax(predictions[0])]
        confidence = np.max(predictions[0])
        
        return {
            'class': predicted_class,
            'confidence': confidence,
            'all_predictions': dict(zip(class_names, predictions[0]))
        }
```

This experience taught me the power of deep learning in solving real-world problems and sparked my interest in pursuing AI/ML further.

## The Evolution: Python Development at Ansys

Joining Ansys as an R&D Engineer marked a significant shift in my career. Here, I transitioned from embedded C to Python development, focusing on:

### Technical Responsibilities
- **PyAnsys Development**: Contributing to the Python ecosystem for simulation software
- **Documentation**: Creating comprehensive Sphinx documentation
- **CI/CD**: Implementing automated testing and deployment pipelines
- **API Design**: Building user-friendly interfaces for complex simulation tools

### Learning Python Ecosystem
```python
# Example of modern Python development practices
from typing import List, Optional
import asyncio
import pytest

class SimulationManager:
    """Manages simulation workflows with async support."""
    
    async def run_simulation(self, 
                           config: dict, 
                           timeout: Optional[float] = None) -> dict:
        """Run simulation with given configuration."""
        try:
            result = await self._execute_simulation(config)
            return self._process_results(result)
        except TimeoutError:
            logger.error(f"Simulation timed out after {timeout}s")
            raise
```

## The Current Focus: RAG-based LLMs

My latest adventure involves developing Retrieval-Augmented Generation (RAG) based Large Language Models. This represents the convergence of all my previous experiences:

### Why RAG?
RAG combines the power of large language models with domain-specific knowledge retrieval, making it perfect for technical documentation and knowledge management - areas where precision and accuracy are crucial.

### Technical Implementation
```python
from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.document_loaders import PyPDFLoader
import os

class RAGSystem:
    """RAG-based question answering system using LangChain."""
    
    def __init__(self, openai_api_key: str):
        os.environ["OPENAI_API_KEY"] = openai_api_key
        self.embeddings = OpenAIEmbeddings()
        self.llm = OpenAI(temperature=0.7, max_tokens=500)
        self.vector_store = None
        self.qa_chain = None
    
    def load_documents(self, pdf_paths: list):
        """Load and process PDF documents."""
        documents = []
        
        for pdf_path in pdf_paths:
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            documents.extend(docs)
        
        # Split documents into chunks
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        split_docs = text_splitter.split_documents(documents)
        return split_docs
    
    def create_vector_store(self, documents):
        """Create vector store from documents."""
        self.vector_store = FAISS.from_documents(
            documents, 
            self.embeddings
        )
        
        # Create retrieval QA chain
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vector_store.as_retriever(
                search_kwargs={"k": 4}
            ),
            return_source_documents=True
        )
    
    def query(self, question: str) -> dict:
        """Query the RAG system."""
        if not self.qa_chain:
            raise ValueError("Vector store not initialized. Call create_vector_store first.")
        
        result = self.qa_chain({"query": question})
        
        return {
            "answer": result["result"],
            "source_documents": [
                {
                    "content": doc.page_content[:200] + "...",
                    "metadata": doc.metadata
                }
                for doc in result["source_documents"]
            ]
        }

# Example usage
rag_system = RAGSystem("your-openai-api-key")

# Load technical documentation
docs = rag_system.load_documents([
    "simulation_manual.pdf",
    "api_documentation.pdf",
    "user_guide.pdf"
])

# Create vector store
rag_system.create_vector_store(docs)

# Query the system
response = rag_system.query(
    "How do I set boundary conditions for thermal analysis?"
)

print(f"Answer: {response['answer']}")
print(f"Sources: {len(response['source_documents'])} documents")
```

### Key Challenges and Solutions

#### 1. **Data Quality and Preprocessing**
- Challenge: Technical documentation varies in format and quality
- Solution: Implemented robust preprocessing pipelines with document parsing and cleaning

#### 2. **Embedding Quality**
- Challenge: Generic embeddings don't capture domain-specific semantics
- Solution: Fine-tuned domain-specific embedding models

#### 3. **Retrieval Accuracy**
- Challenge: Ensuring retrieved documents are truly relevant
- Solution: Implemented hybrid search combining semantic and keyword-based retrieval

#### 4. **Response Quality**
- Challenge: Generating accurate, helpful responses
- Solution: Prompt engineering and response validation mechanisms

## Lessons Learned

### Technical Insights
1. **Foundation Matters**: My embedded systems background taught me to think about constraints and optimization - crucial for efficient AI systems
2. **Iterative Development**: The transition from waterfall (embedded) to agile (AI/ML) development methodologies
3. **Community and Open Source**: The Python/AI community's collaborative approach vs. proprietary embedded development

### Career Development
1. **Continuous Learning**: The AI field evolves rapidly; staying current requires constant learning
2. **Interdisciplinary Skills**: Combining domain expertise (automotive/engineering) with AI capabilities creates unique value
3. **Problem-First Approach**: Focus on solving real problems rather than applying trendy technologies

## Future Directions

Looking ahead, I'm excited about several emerging areas:

### Edge AI
Bringing AI capabilities to embedded systems - combining my original passion with current expertise:
```python
import tensorflow as tf
import numpy as np

class EdgeAIOptimizer:
    """Optimize TensorFlow models for edge deployment."""
    
    def __init__(self):
        self.optimization_methods = ['quantization', 'pruning', 'distillation']
    
    def quantize_model(self, model_path: str, output_path: str):
        """Convert model to TensorFlow Lite with quantization."""
        # Load the model
        model = tf.keras.models.load_model(model_path)
        
        # Create converter
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        
        # Apply post-training quantization
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_types = [tf.float16]
        
        # Convert model
        tflite_model = converter.convert()
        
        # Save quantized model
        with open(output_path, 'wb') as f:
            f.write(tflite_model)
        
        return output_path
    
    def run_edge_inference(self, model_path: str, input_data: np.ndarray):
        """Run inference on edge-optimized model."""
        # Load TensorFlow Lite model
        interpreter = tf.lite.Interpreter(model_path=model_path)
        interpreter.allocate_tensors()
        
        # Get input and output tensors
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Set input tensor
        interpreter.set_tensor(input_details[0]['index'], input_data)
        
        # Run inference
        interpreter.invoke()
        
        # Get output
        output_data = interpreter.get_tensor(output_details[0]['index'])
        return output_data
    
    def benchmark_model(self, model_path: str, test_data: np.ndarray, iterations: int = 100):
        """Benchmark model performance on edge device."""
        import time
        
        interpreter = tf.lite.Interpreter(model_path=model_path)
        interpreter.allocate_tensors()
        
        input_details = interpreter.get_input_details()
        
        # Warm up
        for _ in range(10):
            interpreter.set_tensor(input_details[0]['index'], test_data)
            interpreter.invoke()
        
        # Benchmark
        start_time = time.time()
        for _ in range(iterations):
            interpreter.set_tensor(input_details[0]['index'], test_data)
            interpreter.invoke()
        
        total_time = time.time() - start_time
        avg_inference_time = (total_time / iterations) * 1000  # ms
        
        return {
            'avg_inference_time_ms': avg_inference_time,
            'throughput_fps': 1000 / avg_inference_time,
            'total_time_s': total_time
        }
```

### Automotive AI
The intersection of my automotive background and AI expertise:
- Autonomous driving algorithms using computer vision
- Predictive maintenance systems with time series analysis
- Advanced driver assistance systems (ADAS) with real-time inference

```python
import tensorflow as tf
from tensorflow.keras import layers
import numpy as np

class AutomotiveAISystem:
    """AI system for automotive applications."""
    
    def __init__(self):
        self.lane_detection_model = self._build_lane_detection_model()
        self.predictive_maintenance_model = self._build_maintenance_model()
    
    def _build_lane_detection_model(self):
        """CNN model for lane detection."""
        model = tf.keras.Sequential([
            layers.Conv2D(32, 3, activation='relu', input_shape=(480, 640, 3)),
            layers.Conv2D(64, 3, activation='relu'),
            layers.MaxPooling2D(2),
            layers.Conv2D(128, 3, activation='relu'),
            layers.MaxPooling2D(2),
            layers.Conv2D(256, 3, activation='relu'),
            layers.GlobalAveragePooling2D(),
            layers.Dense(128, activation='relu'),
            layers.Dense(4, activation='sigmoid')  # Lane coordinates
        ])
        
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        return model
    
    def _build_maintenance_model(self):
        """LSTM model for predictive maintenance."""
        model = tf.keras.Sequential([
            layers.LSTM(64, return_sequences=True, input_shape=(100, 5)),  # 100 timesteps, 5 sensors
            layers.LSTM(32, return_sequences=False),
            layers.Dense(16, activation='relu'),
            layers.Dense(1, activation='sigmoid')  # Failure probability
        ])
        
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        return model
    
    def detect_lanes(self, dashboard_camera_frame):
        """Detect lane boundaries in real-time."""
        # Preprocess frame
        frame_resized = tf.image.resize(dashboard_camera_frame, [480, 640])
        frame_normalized = frame_resized / 255.0
        frame_batch = tf.expand_dims(frame_normalized, axis=0)
        
        # Predict lane coordinates
        lane_coords = self.lane_detection_model.predict(frame_batch)
        
        return {
            'left_lane': lane_coords[0][:2],
            'right_lane': lane_coords[0][2:],
            'confidence': tf.reduce_mean(lane_coords).numpy()
        }
    
    def predict_maintenance(self, sensor_time_series):
        """Predict vehicle maintenance needs."""
        # sensor_time_series: [engine_temp, oil_pressure, vibration, rpm, speed]
        sensor_batch = tf.expand_dims(sensor_time_series, axis=0)
        
        failure_probability = self.predictive_maintenance_model.predict(sensor_batch)
        
        return {
            'failure_probability': float(failure_probability[0][0]),
            'maintenance_recommended': failure_probability[0][0] > 0.7,
            'estimated_days_to_failure': int((1 - failure_probability[0][0]) * 100)
        }
```

### Advanced RAG Systems
- Multimodal RAG (text, images, diagrams)
- Real-time knowledge updating
- Domain-specific fine-tuning

```python
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.llms import HuggingFacePipeline
from langchain.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import torch

class AdvancedRAGSystem:
    """Advanced RAG system with conversation memory and local models."""
    
    def __init__(self, model_name="microsoft/DialoGPT-medium"):
        # Use local embeddings model
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # Use local LLM
        self.llm = HuggingFacePipeline.from_model_id(
            model_id=model_name,
            task="text-generation",
            model_kwargs={
                "temperature": 0.7,
                "max_length": 512,
                "device": 0 if torch.cuda.is_available() else -1
            }
        )
        
        # Conversation memory
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        self.vector_store = None
        self.qa_chain = None
    
    def create_knowledge_base(self, documents):
        """Create persistent vector store."""
        self.vector_store = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory="./chroma_db"
        )
        
        # Create conversational retrieval chain
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vector_store.as_retriever(search_kwargs={"k": 5}),
            memory=self.memory,
            return_source_documents=True,
            verbose=True
        )
    
    def chat(self, question: str) -> dict:
        """Have a conversation with the RAG system."""
        if not self.qa_chain:
            raise ValueError("Knowledge base not created. Call create_knowledge_base first.")
        
        result = self.qa_chain({"question": question})
        
        return {
            "answer": result["answer"],
            "source_documents": [
                {
                    "content": doc.page_content[:300] + "...",
                    "source": doc.metadata.get("source", "Unknown"),
                    "page": doc.metadata.get("page", "N/A")
                }
                for doc in result.get("source_documents", [])
            ],
            "chat_history": self.memory.chat_memory.messages
        }
    
    def update_knowledge_base(self, new_documents):
        """Add new documents to existing knowledge base."""
        if self.vector_store:
            self.vector_store.add_documents(new_documents)
            self.vector_store.persist()
        else:
            self.create_knowledge_base(new_documents)
    
    def search_similar_documents(self, query: str, k: int = 5):
        """Search for similar documents without generating an answer."""
        if not self.vector_store:
            raise ValueError("Knowledge base not created.")
        
        similar_docs = self.vector_store.similarity_search(query, k=k)
        
        return [
            {
                "content": doc.page_content,
                "metadata": doc.metadata,
                "similarity_score": None  # Chroma doesn't return scores by default
            }
            for doc in similar_docs
        ]
```

## Conclusion

The journey from embedded systems to AI/ML has been challenging but incredibly rewarding. Each phase has built upon the previous one:

- **Embedded Systems**: Taught me precision, constraints, and systematic thinking
- **Computer Vision**: Introduced me to the power of machine learning
- **Python Development**: Provided tools and ecosystem knowledge
- **RAG-based LLMs**: Combines everything into solving complex, real-world problems

The key insight is that diverse technical backgrounds are actually advantageous in AI/ML. The discipline from embedded systems, the practical focus from robotics, and the software engineering practices from Python development all contribute to building better AI systems.

For anyone considering a similar transition, my advice is:
1. **Leverage your existing expertise** - don't abandon what you know
2. **Start with practical projects** - theory is important, but implementation teaches more
3. **Join the community** - the AI/ML community is incredibly welcoming and collaborative
4. **Stay curious** - the field evolves rapidly, embrace continuous learning

The future lies at the intersection of traditional engineering disciplines and AI. As someone who's navigated this path, I'm excited to see where this journey leads next!

---

*What's your experience with career transitions in tech? I'd love to hear about your journey in the comments or connect on [LinkedIn](https://www.linkedin.com/in/revathy-venugopal-3310b5147/) to discuss further!*